# Journal â€” {{2025-09-13}} â€” {{Building Data Pipeline - Day 1 }}

## 1) What I learned (bullets, not prose)
- Difference between ETL and ELT approaches
- ETL is better for small storage systems (extract only the needed data)
- ELT is used when there's more storage and need for flexibility/scalability
- Industry choice depends on budget, tools, and infrastructure

## 2) New vocabulary (define in your own words)
- ETL - Extract, Transform, Load
- ELT - Extract, Load, Transform 

## 3) Data Engineering mindset applied (what principles did I use?)
-  Raw stays raw: keeping raw data separate from cleaned/transformed data

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- Chose ETL when storage is limited â†’ only extract and keep necessary data
- Chose ELT when there's more storage and need for flexibility (can load raw data and       transform later)
- Assumed that storage cost and compute availability will impact the decision
- Trade-off: ETL is more efficient but less flexible; ELT is more scalable but requires more storage and processing power

## 5) Open questions (things I still donâ€™t get)
- Iâ€™m still unclear about the overall purpose of the setup using DLT and dbt.
- I donâ€™t fully understand how DLT and dbt connect and interact with the database.
- The relationship between schemas, loaded data, and how they are connected is confusing.
- There were errors during the setup, and Iâ€™m not sure what caused them or how to fix them.
- I want to understand the full data flow â€” where data starts, how it moves through different tools, and where it ends up.

## 6) Next actions (small, doable steps)
- [ ] Review basic concepts of DLT and dbt through tutorials or official docs
- [ ] Ask instructor or teammate for a walkthrough of the setup and data flow in the project
- [ ] Practice writing and running simple SQL queries in DBeaver to understand schema and data
- [ ] Debug and fix common errors encountered during setup with help from online forums or peers
- [ ] Document my learnings and questions after each practice session for better understanding

## 7) Artifacts & links (code, queries, dashboards)
- GitHub repo: https://github.com/yourusername/my-ftw-journal
- DBeaver project setup files (SQL scripts, configs)
- Sample journal entry markdown files in `journal/` folder

---

### Mini reflection (3â€“5 sentences)
What surprised me? What would I do differently next time? What will I watch out for in production? What surprised me was how different ETL and ELT approaches are in terms of storage and flexibility, and how companies choose between them based on their infrastructure. Next time, I would spend more time understanding the setup and data flow, especially how tools like DLT and dbt work together. In production, I will watch out for data quality issues and errors during pipeline runs, making sure to have proper monitoring and logging in place.

### BONUS: What is a meme that best describes what you feel or your learning today?
When you try to connect all the dots but end up more confused ðŸ˜‚